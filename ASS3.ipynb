{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ffa401",
   "metadata": {
    "id": "76ffa401"
   },
   "source": [
    "# Assignment 2: Classification and Evaluation (20 marks)\n",
    "\n",
    "Student Name: `Ruijie Hu`\n",
    "\n",
    "Student ID: `1371896`\n",
    "\n",
    "## General info\n",
    "\n",
    "<b>Due date</b>: Monday, 1 September 2023 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -10% per day up to 5 days (both weekdays and weekends count)\n",
    "<ul>\n",
    "    <li>one day late, -2.0;</li>\n",
    "    <li>two days late, -4.0;</li>\n",
    "    <li>three days late, -6.0;</li>\n",
    "    <li>four days late, -8.0;</li>\n",
    "    <li>five days late, -10.0;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Marks</b>:  This assignment will be marked out of 20, and make up 20% of your overall mark for this subject.\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page] on Canvas (under Modules> Coding Resources) for information on the basic setup required for this class, including an iPython notebook viewer and the python packages `numpy`, `pandas`, `matplotlib` and `sklearn`. You can use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions.\n",
    "\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on Canvas>Assignments>Assignmnet2; we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: This assignment is an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/151131/modules#module_825112\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place. Content produced by an AI (including, but not limited to ChatGPT) is not your own work, and submitting such content will be treated as a case of academic misconduct, in line with the <a href=\"https://academicintegrity.unimelb.edu.au/plagiarism-and-collusion/artificial-intelligence-tools-and-technologies\"> University's policy</a>.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions:\n",
    "<UL TYPE=”square”>\n",
    "<LI>Missing Authorship Declaration at the bottom of the page, -2.0\n",
    "<LI>Incomplete or unsigned Authorship Declaration at the bottom of the page, -1.0\n",
    "</UL>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d47f4",
   "metadata": {
    "id": "a66d47f4"
   },
   "source": [
    "## Overview:\n",
    "For this assignment, you will apply a number of classifiers to various datasets, and\n",
    "explore various evaluation paradigms and analyze the impact of multiple parameters on the performance of the classifiers. You will then answer a number of conceptual\n",
    "questions about the Naive Bayes classifier, K-nearest neighbors, and a number of baselines based on your observations.\n",
    "## Data Sets:\n",
    "In this assignment, you will work with two datasets. These datasets are adapted from a UCI archive public dataset:\n",
    "\n",
    " - **Adult**: You predict whether an adult person earns less than 50K or 50K or more US dollar per year, based on various personal attributes like age or education level. More information can be found<a href=\"https://archive.ics.uci.edu/dataset/2/adult\"> here </a>.\n",
    " - **Student**: You predict a student’s final grade {A+, A, B, C, D, F} based on a number of personal and performance related attributes, such as school, parent’s education level, number of absences, etc. More information can be found<a href=\"https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success\"> here </a>.\n",
    "\n",
    "More information about these datasets can be found in `readme.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b26164",
   "metadata": {
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1693287010488,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "d2b26164"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa339cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1693287012775,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "afa339cc",
    "outputId": "e433e755-db40-46ad-f4d8-3a5b1d336a79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\yolo\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.2.2.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d90b111-3c9f-4b4c-a0a6-413000636fc6",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1693287014140,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "4d90b111-3c9f-4b4c-a0a6-413000636fc6"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1c496",
   "metadata": {
    "id": "89a1c496"
   },
   "source": [
    "## Question 1. Reading and Pre-processing [1.5 marks]\n",
    "\n",
    "**A)** First, you will read in the data using the `fileName` parameter into a pandas DataFrame. You will also need to input the list of numerical feature names `num_feat` to the function to make your pre-processing easier.\n",
    "\n",
    "**B)** Second, you replace missing values denoted by `?` using the following two strategies:\n",
    "\n",
    "   * <b>Continuous features</b>: For each feature find the <b>average feature value</b> in the dataset\n",
    "   * <b>Categorical features</b>: For each feature find the <b>most frequent value</b> in the dataset  \n",
    "\n",
    "\n",
    "**C)** Third, you will use one-hot encoding to convert all nominal (and ordinal) attributes to numeric. You can achieve this by either using `get_dummies()` from the pandas library or `OneHotEncoder()` from the scikit-learn library. The resulting dataset includes all originally numeric features as well as the one-hot encoded features that are now numeric, call this data `num_dataset`.\n",
    "\n",
    "**D)** Fourth, you will use **equal-width** binning ( 4 bins ) to convert numerical features into categorical. You can achieve this by using `cut()` from pandas library. The resulting dataset includes all originally categorical features as well as the discretized features that are now categorical, call this data `cat_dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c33a9d2",
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1693295678814,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "9c33a9d2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess(fileName1, fileName2):\n",
    "    ## read the csv files\n",
    "    data1 = pd.read_csv(fileName1)\n",
    "    data2 = pd.read_csv(fileName2)\n",
    "\n",
    "    # Drop the first column of data2\n",
    "    data2 = data2.drop(data2.columns[0], axis=1)\n",
    "\n",
    "    # Check if the number of rows in both datasets are the same\n",
    "    if len(data1) != len(data2):\n",
    "        raise ValueError(\"The number of rows in the two datasets do not match!\")\n",
    "\n",
    "    # Concatenate data2 (word embeddings) with 'rating' and 'dr-id-adjusted' columns from data1\n",
    "    merged_data = pd.concat([data1[['dr-id-adjusted', 'rating']], data2], axis=1)\n",
    "\n",
    "    # Splitting the dataset into features and target\n",
    "    # Assuming all other columns except 'rating' in merged_data are features\n",
    "    features = merged_data.drop(columns=['rating'])\n",
    "    target = merged_data['rating']\n",
    "\n",
    "    return merged_data, features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continental-administration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1693287164564,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "continental-administration",
    "outputId": "8c95ffa9-9549-4869-bb2d-7828b995e263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43003\n",
      "5500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr-id-adjusted</th>\n",
       "      <th>rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33620</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.022207</td>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.021580</td>\n",
       "      <td>-0.063474</td>\n",
       "      <td>-0.060289</td>\n",
       "      <td>0.057354</td>\n",
       "      <td>0.066238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033674</td>\n",
       "      <td>-0.055816</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>-0.035806</td>\n",
       "      <td>-0.016576</td>\n",
       "      <td>0.040326</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>-0.029757</td>\n",
       "      <td>-0.063486</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33620</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>0.039449</td>\n",
       "      <td>0.025721</td>\n",
       "      <td>0.024461</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>-0.025881</td>\n",
       "      <td>-0.007678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088275</td>\n",
       "      <td>-0.104800</td>\n",
       "      <td>-0.039734</td>\n",
       "      <td>-0.038932</td>\n",
       "      <td>-0.067038</td>\n",
       "      <td>-0.025953</td>\n",
       "      <td>-0.077584</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>-0.091612</td>\n",
       "      <td>-0.016109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33626</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>-0.004742</td>\n",
       "      <td>-0.015077</td>\n",
       "      <td>0.026958</td>\n",
       "      <td>-0.061960</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.038323</td>\n",
       "      <td>0.099361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.056154</td>\n",
       "      <td>0.024323</td>\n",
       "      <td>-0.017221</td>\n",
       "      <td>-0.075064</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>-0.072174</td>\n",
       "      <td>-0.020699</td>\n",
       "      <td>-0.057820</td>\n",
       "      <td>0.039419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33626</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.014154</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.045189</td>\n",
       "      <td>-0.076433</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.019410</td>\n",
       "      <td>0.068679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>0.029588</td>\n",
       "      <td>-0.022354</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>-0.082329</td>\n",
       "      <td>0.040468</td>\n",
       "      <td>-0.015963</td>\n",
       "      <td>-0.068362</td>\n",
       "      <td>-0.050644</td>\n",
       "      <td>0.096260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33628</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.069949</td>\n",
       "      <td>-0.012617</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>-0.041826</td>\n",
       "      <td>-0.076924</td>\n",
       "      <td>-0.057929</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>-0.029924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021068</td>\n",
       "      <td>-0.038854</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>0.026084</td>\n",
       "      <td>0.134875</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>-0.051483</td>\n",
       "      <td>-0.014984</td>\n",
       "      <td>0.006698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>38063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.063899</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>-0.076222</td>\n",
       "      <td>-0.052318</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.067840</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>-0.027531</td>\n",
       "      <td>-0.051565</td>\n",
       "      <td>-0.057745</td>\n",
       "      <td>-0.026203</td>\n",
       "      <td>-0.160159</td>\n",
       "      <td>-0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>38064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.027958</td>\n",
       "      <td>-0.021277</td>\n",
       "      <td>0.022908</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>-0.139231</td>\n",
       "      <td>-0.047026</td>\n",
       "      <td>-0.070944</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.103551</td>\n",
       "      <td>-0.042511</td>\n",
       "      <td>-0.064135</td>\n",
       "      <td>0.052720</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>0.015123</td>\n",
       "      <td>-0.008484</td>\n",
       "      <td>0.012005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>38065</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.052219</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>-0.076079</td>\n",
       "      <td>-0.029523</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>0.104013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018229</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>-0.071201</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>-0.092275</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>38065</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.083509</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>-0.119880</td>\n",
       "      <td>-0.060715</td>\n",
       "      <td>-0.020452</td>\n",
       "      <td>0.030014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.024247</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>-0.046223</td>\n",
       "      <td>-0.025451</td>\n",
       "      <td>0.105774</td>\n",
       "      <td>-0.067439</td>\n",
       "      <td>-0.058233</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.006985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>38065</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078557</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.031399</td>\n",
       "      <td>-0.077252</td>\n",
       "      <td>-0.059105</td>\n",
       "      <td>-0.043341</td>\n",
       "      <td>0.080183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029402</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>-0.080647</td>\n",
       "      <td>-0.038833</td>\n",
       "      <td>0.102256</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>-0.012821</td>\n",
       "      <td>0.038186</td>\n",
       "      <td>0.039774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dr-id-adjusted  rating         0         1         2         3  \\\n",
       "0              33620       1 -0.022207  0.064185  0.023957  0.021580   \n",
       "1              33620      -1 -0.047829  0.039449  0.025721  0.024461   \n",
       "2              33626       1 -0.015018 -0.004742 -0.015077  0.026958   \n",
       "3              33626       1 -0.014154 -0.015275  0.032033  0.045189   \n",
       "4              33628       1 -0.069949 -0.012617  0.035879 -0.041826   \n",
       "...              ...     ...       ...       ...       ...       ...   \n",
       "5495           38063       1  0.006699  0.033123  0.003509  0.063899   \n",
       "5496           38064       1 -0.027958 -0.021277  0.022908  0.005755   \n",
       "5497           38065       1 -0.052219 -0.011069  0.007917  0.008442   \n",
       "5498           38065       1 -0.000394 -0.083509  0.002389  0.039134   \n",
       "5499           38065       1 -0.078557  0.001306  0.024693  0.031399   \n",
       "\n",
       "             4         5         6         7  ...       374       375  \\\n",
       "0    -0.063474 -0.060289  0.057354  0.066238  ... -0.033674 -0.055816   \n",
       "1     0.013234 -0.007365 -0.025881 -0.007678  ...  0.088275 -0.104800   \n",
       "2    -0.061960  0.000557  0.038323  0.099361  ...  0.025605  0.056154   \n",
       "3    -0.076433 -0.001758 -0.019410  0.068679  ... -0.009228  0.029588   \n",
       "4    -0.076924 -0.057929  0.026214 -0.029924  ... -0.021068 -0.038854   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "5495  0.020196 -0.076222 -0.052318  0.042699  ...  0.000500  0.067840   \n",
       "5496 -0.139231 -0.047026 -0.070944  0.033015  ...  0.024188  0.012772   \n",
       "5497 -0.076079 -0.029523 -0.030472  0.104013  ...  0.018229  0.026702   \n",
       "5498 -0.119880 -0.060715 -0.020452  0.030014  ...  0.017917  0.024247   \n",
       "5499 -0.077252 -0.059105 -0.043341  0.080183  ... -0.029402  0.049520   \n",
       "\n",
       "           376       377       378       379       380       381       382  \\\n",
       "0     0.013047 -0.035806 -0.016576  0.040326  0.005111 -0.029757 -0.063486   \n",
       "1    -0.039734 -0.038932 -0.067038 -0.025953 -0.077584  0.018969 -0.091612   \n",
       "2     0.024323 -0.017221 -0.075064  0.007564 -0.072174 -0.020699 -0.057820   \n",
       "3    -0.022354 -0.013990 -0.082329  0.040468 -0.015963 -0.068362 -0.050644   \n",
       "4     0.042229 -0.022856  0.026084  0.134875  0.022401 -0.051483 -0.014984   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5495  0.030330 -0.008184 -0.027531 -0.051565 -0.057745 -0.026203 -0.160159   \n",
       "5496  0.103551 -0.042511 -0.064135  0.052720 -0.005511  0.015123 -0.008484   \n",
       "5497 -0.071201 -0.036976 -0.092275  0.027811  0.011771  0.012291  0.025588   \n",
       "5498 -0.003603 -0.046223 -0.025451  0.105774 -0.067439 -0.058233  0.051917   \n",
       "5499  0.018761 -0.080647 -0.038833  0.102256 -0.044145 -0.012821  0.038186   \n",
       "\n",
       "           383  \n",
       "0     0.000462  \n",
       "1    -0.016109  \n",
       "2     0.039419  \n",
       "3     0.096260  \n",
       "4     0.006698  \n",
       "...        ...  \n",
       "5495 -0.000017  \n",
       "5496  0.012005  \n",
       "5497  0.010331  \n",
       "5498  0.006985  \n",
       "5499  0.039774  \n",
       "\n",
       "[5500 rows x 386 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the data\n",
    "dataset_train, features_train,target_train = preprocess(\"D:/unimelb-3rd/IML/ASS3/dataset/TRAIN.csv\",\"D:/unimelb-3rd/IML/ASS3/dataset/384EMBEDDINGS_TRAIN.csv\")\n",
    "dataset_val, features_val, target_val = preprocess(\"D:/unimelb-3rd/IML/ASS3/dataset/VALIDATION.csv\",\"D:/unimelb-3rd/IML/ASS3/dataset/384EMBEDDINGS_VALIDATION.csv\")\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_val))\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-joint",
   "metadata": {
    "id": "fourth-joint"
   },
   "source": [
    "#### Question 2 . Baseline methods and Discussion [4.5 marks]\n",
    "**A)** For 10 rounds, use `train_test_split` to divide the processed `cat_dataset` into 80% train, 20% test . Set the `random_state` equal to the loop counter. For example in the loop\n",
    "``` python\n",
    "for i in range(10):\n",
    "```\n",
    "make `random_state` equal to `i`.\n",
    "Use the splitted datasets to train and test the following models: **[1 mark]**\n",
    "\n",
    "- Zero-R\n",
    "- One-R\n",
    "- Weighted Random\n",
    "\n",
    "Report the average accuracy over the 10 runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "south-opera",
   "metadata": {
    "id": "south-opera"
   },
   "outputs": [],
   "source": [
    "## You can define your helper functions for One-R or other baselines in this block\n",
    "## for One-R at training time, you can break the ties randomly\n",
    "## for One-R at prediction time, if the test contains an unseen feature value, return the majority class\n",
    "# Zero-R Classifier\n",
    "import random\n",
    "def one_r_classifier(train_x, train_y):\n",
    "    best_error = float('inf')\n",
    "    best_rules = {}\n",
    "    best_attribute = None\n",
    "    majority_class = train_y.mode()[0]\n",
    "\n",
    "    for attribute in train_x.columns:\n",
    "        rules = {}\n",
    "        error_count = 0\n",
    "\n",
    "        for value in pd.unique(train_x[attribute]):\n",
    "            # Get the most common class for this attribute value\n",
    "            possible_classes = train_y[train_x[attribute] == value].value_counts()\n",
    "\n",
    "            # If there's a tie, pick randomly\n",
    "            if len(possible_classes) > 1 and possible_classes.iloc[0] == possible_classes.iloc[1]:\n",
    "                chosen_class = random.choice(possible_classes.index[:2])\n",
    "            else:\n",
    "                chosen_class = possible_classes.idxmax()\n",
    "\n",
    "            rules[value] = chosen_class\n",
    "            error_count += sum(train_y[train_x[attribute] == value] != chosen_class)\n",
    "\n",
    "        # If this attribute has a lower error than the best so far, update best_rules and best_attribute\n",
    "        if error_count < best_error:\n",
    "            best_error = error_count\n",
    "            best_rules = rules\n",
    "            best_attribute = attribute\n",
    "\n",
    "    # Return the lambda function for prediction and the best attribute\n",
    "    return lambda x: best_rules.get(x[best_attribute], majority_class), best_attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e3d435-af7a-4bd4-b481-f22b1c7550a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3903,
     "status": "ok",
     "timestamp": 1693216192129,
     "user": {
      "displayName": "Ruijie HU",
      "userId": "08766390301904266715"
     },
     "user_tz": -600
    },
    "id": "07e3d435-af7a-4bd4-b481-f22b1c7550a2",
    "outputId": "8565620c-bc8f-4974-c7e1-e87f5110014f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ZeroR: 0.73\n",
      "Accuracy of Weighted Random: 0.6\n"
     ]
    }
   ],
   "source": [
    "def baselines(dataset_train,dataset_val):\n",
    "\n",
    "    ZeroR_Acc_1 = []\n",
    "    WRand_Acc_1 = []\n",
    "\n",
    "    ## your code here\n",
    "    report = []\n",
    "    train_x, train_y = dataset_train.drop(['rating'],axis = 1), dataset_train['rating']\n",
    "    val_x, val_y = dataset_val.drop(['rating'], axis=1), dataset_val['rating']\n",
    "\n",
    "      # Train and test Zero-R\n",
    "    zero_r = DummyClassifier(strategy='most_frequent')\n",
    "    zero_r.fit(train_x, train_y)\n",
    "    zero_r_predictions = zero_r.predict(val_x)\n",
    "    zero_r_accuracy = sum(1 for pred, true in zip(zero_r_predictions, val_y) if pred == true) / len(val_y)\n",
    "    report_zero = classification_report(val_y,zero_r_predictions,zero_division=0)\n",
    "    report.append(report_zero)\n",
    "    ZeroR_Acc_1.append(zero_r_accuracy)\n",
    "\n",
    "      # Train and test Weighted Random\n",
    "    weighted_random = DummyClassifier(strategy='stratified')\n",
    "    weighted_random.fit(train_x, train_y)\n",
    "    weighted_random_predictions = weighted_random.predict(val_x)\n",
    "    report_w = classification_report(val_y, weighted_random_predictions,zero_division=0)\n",
    "    report.append(report_w)\n",
    "    weighted_random_accuracy = sum(1 for pred, true in zip(weighted_random_predictions, val_y) if pred == true) / len(val_y)\n",
    "    WRand_Acc_1.append(weighted_random_accuracy)\n",
    "\n",
    "\n",
    "    print(\"Accuracy of ZeroR:\", np.mean(ZeroR_Acc_1).round(2))\n",
    "    print(\"Accuracy of Weighted Random:\", np.mean(WRand_Acc_1).round(2))\n",
    "    #print(report[0])\n",
    "    #print(report[1])\n",
    "    #print(report[2])\n",
    "    # Print the most often selected feature\n",
    "\n",
    "\n",
    "##Adult Dataset and Student Dataset results:\n",
    "baselines(dataset_train,dataset_val)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
